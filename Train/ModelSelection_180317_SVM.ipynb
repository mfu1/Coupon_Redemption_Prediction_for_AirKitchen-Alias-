{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode, entropy\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, precision_score, recall_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "#from pyspark.sql import SQLContext, Row, DataFrameWriter\n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir('/Users/meif/Desktop/SI 699')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# continuous and categorical\n",
    "mains = [\"user_coupon\", \"user_id\", \"coupon_id\", \"start_time\", \"is_used\"]\n",
    "\n",
    "categorical = ['sex_1', 'sex_2', \n",
    "               'age_60', 'age_70', 'age_80', 'age_90', 'age_0', \n",
    "               'city1', 'city2', 'city3', 'city4', 'city5', \n",
    "               'AppVerLast_2.1', 'AppVerLast_2.2', 'AppVerLast_2.3', 'AppVerLast_2.4', 'AppVerLast_2.5', 'AppVerLast_2.7', 'AppVerLast_2.8',\n",
    "               'covers_mon', 'covers_tue', 'covers_wed', 'covers_thu', 'covers_fri', 'covers_sat', 'covers_sun', \n",
    "               'type1', 'type6', \n",
    "               'Complaints', 'Eventsoperation', 'NewUserCouponPackageByBD', 'PreUserCouponCode', 'RecallUserDaily', 'home201603222253', \n",
    "               'home_dongbeiguan', 'home_jiangzhecai', 'home_muqinjie', 'home_xiangcaiguan', 'preuser', 'shareuser', \n",
    "               '商家拒单返券', '家厨发券', '活动赠券', '码兑券', '自运营赠券', '蒲公英受邀',\n",
    "               'CoupUseLast']\n",
    "\n",
    "conitnuous = ['kitchen_entropy', \n",
    "              'distance_median', 'distance_std',\n",
    "              'user_longitude_median', 'user_longitude_std', 'user_latitude_median', 'user_latitude_std', \n",
    "              'coupon_effective_days', 'money', 'max_money', \n",
    "              'WeeklyCouponUsedCount', \"BiWeeklyCouponUsedCount\",\n",
    "              'WeeklyOrderCount', 'BiWeeklyOrderCount',\n",
    "              'coupon_usage_rate', 'order_coupon_usage_rate',\n",
    "              'coupon_type1_usage_rate', 'coupon_type6_usage_rate',\n",
    "              'coupon_used_weekend_perc', 'order_weekend_perc', \n",
    "              'worth_money_median', 'worth_money_std', \n",
    "              'InterCoup', 'InterOrder', 'Recency']\n",
    "\n",
    "# take_log= ['Recency_log', 'InterCoup_log', 'InterOrder_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5484528\n",
      "['sex_1', 'sex_2', 'age_60', 'age_70', 'age_80', 'age_90', 'age_0', 'city1', 'city2', 'city3', 'city4', 'city5', 'AppVerLast_2.1', 'AppVerLast_2.2', 'AppVerLast_2.3', 'AppVerLast_2.4', 'AppVerLast_2.5', 'AppVerLast_2.7', 'AppVerLast_2.8', 'kitchen_entropy', 'distance_median', 'distance_std', 'user_longitude_median', 'user_longitude_std', 'user_latitude_median', 'user_latitude_std', 'coupon_effective_days', 'money', 'max_money', 'covers_mon', 'covers_tue', 'covers_wed', 'covers_thu', 'covers_fri', 'covers_sat', 'covers_sun', 'type1', 'type6', 'Complaints', 'Eventsoperation', 'NewUserCouponPackageByBD', 'PreUserCouponCode', 'RecallUserDaily', 'home201603222253', 'home_dongbeiguan', 'home_jiangzhecai', 'home_muqinjie', 'home_xiangcaiguan', 'preuser', 'shareuser', '\\xe5\\x95\\x86\\xe5\\xae\\xb6\\xe6\\x8b\\x92\\xe5\\x8d\\x95\\xe8\\xbf\\x94\\xe5\\x88\\xb8', '\\xe5\\xae\\xb6\\xe5\\x8e\\xa8\\xe5\\x8f\\x91\\xe5\\x88\\xb8', '\\xe6\\xb4\\xbb\\xe5\\x8a\\xa8\\xe8\\xb5\\xa0\\xe5\\x88\\xb8', '\\xe7\\xa0\\x81\\xe5\\x85\\x91\\xe5\\x88\\xb8', '\\xe8\\x87\\xaa\\xe8\\xbf\\x90\\xe8\\x90\\xa5\\xe8\\xb5\\xa0\\xe5\\x88\\xb8', '\\xe8\\x92\\xb2\\xe5\\x85\\xac\\xe8\\x8b\\xb1\\xe5\\x8f\\x97\\xe9\\x82\\x80', 'coupon_usage_rate', 'order_coupon_usage_rate', 'coupon_type1_usage_rate', 'coupon_type6_usage_rate', 'coupon_used_weekend_perc', 'order_weekend_perc', 'worth_money_median', 'worth_money_std', 'InterCoup', 'InterOrder', 'Recency', 'CoupUseLast', 'WeeklyCouponUsedCount', 'BiWeeklyCouponUsedCount', 'WeeklyOrderCount', 'BiWeeklyOrderCount']\n"
     ]
    }
   ],
   "source": [
    "trainset = pd.read_csv(\"Dataset/trainset_180314.csv\").iloc[:,1:]\n",
    "testset = pd.read_csv(\"Dataset/testset_180314.csv\").iloc[:,1:]\n",
    "print(len(trainset) + len(testset))\n",
    "print(trainset.columns[5:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization: CV, SCALER, KERNEL\n",
    "CV = \"3\" # 3\n",
    "if CV == \"1\":\n",
    "    cv = [0]\n",
    "elif CV == \"2\":\n",
    "    cv = [3]\n",
    "elif CV == \"3\":\n",
    "    cv = [0,1,2,3]\n",
    "\n",
    "SCALER = \"1\" # 1\n",
    "if SCALER == \"1\":\n",
    "    scaler = MinMaxScaler()\n",
    "elif SCALER == \"2\":\n",
    "    scaler = StandardScaler()\n",
    "elif SCALER == \"3\":\n",
    "    scaler = MaxAbsScaler()\n",
    "elif SCALER == \"4\":\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "KERNEL = \"rbf\"  # or rbf, poly\n",
    "if KERNEL == \"linear\":\n",
    "    C = [0.01, 0.1, 1, 10, 100]\n",
    "    G = [0]\n",
    "else:\n",
    "    C = [0.01, 0.1, 1, 10, 100] #  A low C makes the decision surface smooth, while a high C select more samples as support vectors\n",
    "    G = [0.01, 0.1, 1, 10] # low values meaning far and high values meaning close\n",
    "\n",
    "BALANCE = int(\"2\") # 2\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaling\n",
    "X_train_continuous = scaler.fit_transform(trainset[conitnuous])\n",
    "X_test_continuous = scaler.transform(testset[conitnuous])\n",
    "\n",
    "trainset_scaled = pd.concat([trainset.loc[:,mains + categorical], pd.DataFrame(X_train_continuous, columns = conitnuous)], axis=1)\n",
    "testset_scaled = pd.concat([testset.loc[:,mains + categorical], pd.DataFrame(X_test_continuous, columns = conitnuous)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train & dev\n",
    "split_date1 = \"2016-04-15\"\n",
    "split_date2 = \"2016-04-22\"\n",
    "split_date3 = \"2016-04-29\"\n",
    "split_date4 = \"2016-05-06\"\n",
    "\n",
    "trainset1 = trainset_scaled[trainset_scaled[\"start_time\"] <= split_date1]\n",
    "devset1 = trainset_scaled[(trainset_scaled[\"start_time\"] > split_date1) & (trainset_scaled[\"start_time\"] <= split_date2)]\n",
    "\n",
    "trainset2 = trainset_scaled[trainset_scaled[\"start_time\"] <= split_date2]\n",
    "devset2 = trainset_scaled[(trainset_scaled[\"start_time\"] > split_date2) & (trainset_scaled[\"start_time\"] <= split_date3)]\n",
    "\n",
    "trainset3 = trainset_scaled[trainset_scaled[\"start_time\"] <= split_date3]\n",
    "devset3 = trainset_scaled[(trainset_scaled[\"start_time\"] > split_date3) & (trainset_scaled[\"start_time\"] <= split_date4)]\n",
    "\n",
    "trainset4 = trainset_scaled[trainset_scaled[\"start_time\"] <= split_date4]\n",
    "devset4 = trainset_scaled[trainset_scaled[\"start_time\"] > split_date4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle trainset\n",
    "trainset1 = trainset1.iloc[shuffle(trainset1.index).tolist(),]\n",
    "trainset2 = trainset2.iloc[shuffle(trainset2.index).tolist(),]\n",
    "trainset3 = trainset3.iloc[shuffle(trainset3.index).tolist(),]\n",
    "trainset4 = trainset4.iloc[shuffle(trainset4.index).tolist(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainsets = [trainset1, trainset2, trainset3, trainset4]\n",
    "devsets = [devset1, devset2, devset3, devset4]\n",
    "\n",
    "X_trains, y_trains, X_devs, y_devs = [], [], [], []\n",
    "for i in trainsets:\n",
    "    X_trains.append(i[i.columns[5:]])\n",
    "    y_trains.append(i[\"is_used\"])\n",
    "for i in devsets:\n",
    "    X_devs.append(i[i.columns[5:]])\n",
    "    y_devs.append(i[\"is_used\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset_all = trainset_scaled\n",
    "trainset_all = trainset_all.iloc[shuffle(trainset_all.index).tolist(),]\n",
    "X_train_all = trainset_all.iloc[:,5:]\n",
    "y_train_all = trainset_all[\"is_used\"]\n",
    "\n",
    "X_test = testset_scaled.iloc[:,5:]\n",
    "y_test = testset_scaled[\"is_used\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'user_coupon', u'user_id', u'coupon_id', u'start_time', u'is_used',\n",
       "       u'sex_1', u'sex_2', u'age_60', u'age_70', u'age_80', u'age_90',\n",
       "       u'age_0', u'city1', u'city2', u'city3', u'city4', u'city5',\n",
       "       u'AppVerLast_2.1', u'AppVerLast_2.2', u'AppVerLast_2.3',\n",
       "       u'AppVerLast_2.4', u'AppVerLast_2.5', u'AppVerLast_2.7',\n",
       "       u'AppVerLast_2.8', u'kitchen_entropy', u'distance_median',\n",
       "       u'distance_std', u'user_longitude_median', u'user_longitude_std',\n",
       "       u'user_latitude_median', u'user_latitude_std', u'coupon_effective_days',\n",
       "       u'money', u'max_money', u'covers_mon', u'covers_tue', u'covers_wed',\n",
       "       u'covers_thu', u'covers_fri', u'covers_sat', u'covers_sun', u'type1',\n",
       "       u'type6', u'Complaints', u'Eventsoperation',\n",
       "       u'NewUserCouponPackageByBD', u'PreUserCouponCode', u'RecallUserDaily',\n",
       "       u'home201603222253', u'home_dongbeiguan', u'home_jiangzhecai',\n",
       "       u'home_muqinjie', u'home_xiangcaiguan', u'preuser', u'shareuser',\n",
       "       u'商家拒单返券', u'家厨发券', u'活动赠券', u'码兑券', u'自运营赠券', u'蒲公英受邀',\n",
       "       u'coupon_usage_rate', u'order_coupon_usage_rate',\n",
       "       u'coupon_type1_usage_rate', u'coupon_type6_usage_rate',\n",
       "       u'coupon_used_weekend_perc', u'order_weekend_perc',\n",
       "       u'worth_money_median', u'worth_money_std', u'InterCoup', u'InterOrder',\n",
       "       u'Recency', u'CoupUseLast', u'WeeklyCouponUsedCount',\n",
       "       u'BiWeeklyCouponUsedCount', u'WeeklyOrderCount', u'BiWeeklyOrderCount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'AUC': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'Accuracy': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'BALANCE': 2,\n",
       "             'F05': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'KERNEL': 'rbf',\n",
       "             'Mean_Pre': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'Precision': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'Recall': defaultdict(<function __main__.<lambda>>,\n",
       "                         {'0.01': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '0.1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '1': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '10': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []}),\n",
       "                          '100': defaultdict(<function __main__.<lambda>>,\n",
       "                                      {'0.01': [],\n",
       "                                       '0.1': [],\n",
       "                                       '1': [],\n",
       "                                       '10': []})}),\n",
       "             'SCALER': '1'})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_svm = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: list))))\n",
    "res_svm[\"KERNEL\"] = KERNEL\n",
    "res_svm[\"SCALER\"] = SCALER\n",
    "res_svm[\"BALANCE\"] = BALANCE\n",
    "\n",
    "evaluations = [\"F05\", \"Precision\", \"Recall\", \"Mean_Pre\", \"AUC\", \"Accuracy\"]\n",
    "for ev in evaluations:\n",
    "    for c in C:\n",
    "        for g in G:\n",
    "            res_svm[ev][str(c)][str(g)] = []\n",
    "res_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train\n",
    "start_time = time.time()\n",
    "\n",
    "for c in C:\n",
    "    start_time2 = time.time()\n",
    "    for g in G:\n",
    "        start_time3 = time.time()\n",
    "            \n",
    "        for n in cv:\n",
    "            if KERNEL == \"linear\":\n",
    "                # 5 hours\n",
    "                svc = LinearSVC(C=c, \n",
    "                                class_weight={1: BALANCE},\n",
    "                                random_state=RANDOM_STATE)\n",
    "            else:\n",
    "                svc = SVC(C=c, gamma=g, \n",
    "                          kernel = KERNEL,\n",
    "                          class_weight={1: BALANCE},\n",
    "                          random_state=RANDOM_STATE)\n",
    "                \n",
    "            svc.fit(X_trains[n], y_trains[n])\n",
    "            y_pred = svc.predict(X_devs[n])\n",
    "            y_dev = y_devs[n]\n",
    "\n",
    "            print(\"K: {}, CV: {}, C: {}, G: {}\".format(KERNEL, n, c, g))\n",
    "            print(confusion_matrix(y_dev, y_pred, labels=[1,0]))\n",
    "            \n",
    "            f05 = fbeta_score(y_dev, y_pred, beta=0.5, labels=[1,0])\n",
    "            precision = precision_score(y_dev, y_pred, labels=[1,0])\n",
    "            recall = recall_score(y_dev, y_pred, labels=[1,0])\n",
    "            mp = average_precision_score(y_dev, y_pred)\n",
    "            auc = roc_auc_score(y_dev, y_pred)\n",
    "            acc = accuracy_score(y_dev, y_pred)\n",
    "            evaluations_res = [f05, precision, recall, mp, auc, acc]\n",
    "            \n",
    "            for i in range(len(evaluations)):\n",
    "                print(\"{}: {}\".format(evaluations[i], evaluations_res[i]))\n",
    "                res_svm[evaluations[i]][str(c)][str(g)].append(evaluations_res[i])\n",
    "            print(\"\\n\")\n",
    "                \n",
    "        print(\"Finished c {} g {} in {} sec\\n\".format(c, g, time.time() - start_time3))\n",
    "            \n",
    "    print(\"Finished c {} in {} sec\\n\".format(c, time.time() - start_time2))\n",
    "        \n",
    "print(\"{} sec\\n\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# average cv results\n",
    "for ev in evaluations:\n",
    "    for c in res_svm[ev]:\n",
    "        res_svm[ev][c] = {g:np.mean(res_svm[ev][c][g]) for g in res_svm[ev][c]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save param output\n",
    "with open('ParamResults/KernalSVM/json/res_svm_{}_{}_1v{}.json'.format(KERNEL, SCALER, BALANCE), 'w') as f:\n",
    "    json.dump(res_svm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load params\n",
    "res_svm_rbf_minmax_1v2 = json.load(open(\"ParamResults/KernalSVM/json/res_svm_rbf_1_1v2.json\"))\n",
    "res_svm_rbf_maxabs_1v2 = json.load(open(\"ParamResults/KernalSVM/json/res_svm_rbf_3_1v2.json\"))\n",
    "res_svm_poly_minmax_1v2 = json.load(open(\"ParamResults/KernalSVM/json/res_svm_poly_1_1v2.json\"))\n",
    "res_svm_poly_maxabs_1v2 = json.load(open(\"ParamResults/KernalSVM/json/res_svm_poly_3_1v2.json\"))\n",
    "# pprint(res_svm_poly_maxabs_1v2)\n",
    "\n",
    "evaluations = [\"F05\", \"Precision\", \"Recall\", \"Mean_Pre\", \"AUC\", \"Accuracy\"]\n",
    "C = [\"0.01\", \"0.1\", \"1\", \"10\", \"100\"]\n",
    "G = [\"0.01\", \"0.1\", \"1\", \"10\"]\n",
    "cs = [float(j) for i in [[c]*len(G) for c in C] for j in i]\n",
    "gs = [float(i) for i in G*len(C)]\n",
    "\n",
    "plot_svm_rbf_minmax_1v2 = {ev: [list(res_svm_rbf_minmax_1v2[ev][c].values()) for c in C] for ev in evaluations}\n",
    "plot_svm_rbf_maxabs_1v2 = {ev: [list(res_svm_rbf_maxabs_1v2[ev][c].values()) for c in C] for ev in evaluations}\n",
    "plot_svm_poly_minmax_1v2 = {ev: [list(res_svm_poly_minmax_1v2[ev][c].values()) for c in C] for ev in evaluations}\n",
    "plot_svm_poly_maxabs_1v2 = {ev: [list(res_svm_poly_maxabs_1v2[ev][c].values()) for c in C] for ev in evaluations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "for i in range(len(evaluations)):\n",
    "    fig = plt.figure(i + 1)\n",
    "    \n",
    "    plt.title(evaluations[i] + \" Score\", y=1.14, fontweight=\"bold\")\n",
    "    plt.grid(True, linestyle='--', color='#CCCCCC')\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    ax_1 = plot_svm_rbf_minmax_1v2[evaluations[i]]\n",
    "    ax_2 = plot_svm_rbf_maxabs_1v2[evaluations[i]]\n",
    "    ax_3 = plot_svm_poly_minmax_1v2[evaluations[i]]\n",
    "    ax_4 = plot_svm_poly_maxabs_1v2[evaluations[i]]\n",
    "    \n",
    "    all_scores = [j for i in ax_1 for j in i] + [j for i in ax_2 for j in i] + [j for i in ax_3 for j in i] + [j for i in ax_4 for j in i]\n",
    "    maxIdx = np.argmax(np.array(all_scores))\n",
    "    maxScore = max(all_scores)\n",
    "    minScore = min(all_scores)\n",
    "    \n",
    "    ax.set_xlabel('C')\n",
    "    ax.set_ylabel('gamma')\n",
    "    ax.set_zlabel('Score')\n",
    "    ax.set_zlim(minScore*0.999, maxScore*1.003)\n",
    "\n",
    "    ax.scatter(cs, gs, [j for i in ax1_1 for j in i], label=\"svm_rbf_minmax_1v2\", c='pink', marker='o')\n",
    "    ax.scatter(cs, gs, [j for i in ax1_2 for j in i], label=\"svm_rbf_maxabs_1v2\", c='red', marker='o')\n",
    "    ax.scatter(cs, gs, [j for i in ax1_3 for j in i], label=\"svm_poly_minmax_1v2\", c='#6699CC', marker='^')\n",
    "    ax.scatter(cs, gs, [j for i in ax1_4 for j in i], label=\"svm_poly_maxabs_1v2\", c='#6666FF', marker='^')\n",
    "    ax.legend(bbox_to_anchor=(0.7, 0.2), loc=2, borderaxespad=0.)\n",
    "\n",
    "    ax.text(maxIdx//5, maxIdx%5, maxScore*1.0005, \n",
    "            'Max: {0:.4f}'.format(maxScore)) \n",
    "\n",
    "    plt.savefig('SVM_{}.png'.format(evaluations[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrain using selected params\n",
    "c, g, k, b, rs = 0.05, 0.01, 'rbf', 2, 42\n",
    "svm_best = SVC(C=c, gamma=g, \n",
    "               kernel = k,\n",
    "               class_weight={1: BALANCE},\n",
    "               random_state=RANDOM_STATE)\n",
    "svm_best.fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attributes\n",
    "# svm_best.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = svm_best.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "print(\"F05: {}\".format(fbeta_score(y_test, y_pred, beta=0.5, labels=[1,0])))\n",
    "print(\"Precision: {}\".format(precision_score(y_test, y_pred, labels=[1,0])))\n",
    "print(\"Recall: {}\".format(recall_score(y_test, y_pred, labels=[1,0])))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
